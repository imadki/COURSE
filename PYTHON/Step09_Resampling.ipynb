{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Performance of Machine Learning Algorithms with Resampling\n",
    "\n",
    "\n",
    "\n",
    "- The best way to evaluate the performance of an algorithm would be to make predictions for new data to which you already know the answers. \n",
    "\n",
    "- The second best way is to use clever techniques from statistics called resampling methods that allow you to make accurate estimates for how well your algorithm will perform on new data.\n",
    "\n",
    "\n",
    "    1. Train and Test Sets.\n",
    "    2. k-fold Cross Validation.\n",
    "    3. Leave One Out Cross Validation.\n",
    "    4. Repeated Random Test-Train Splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using a train and a test set\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "filename = 'data/05/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Train and Test Sets.\n",
    "\n",
    "- The simplest method that we can use to evaluate the performance of a machine learning algorithm is to use different training and testing datasets. \n",
    "\n",
    "- We can take our original dataset and split it into two parts. Train the algorithm on the first part, make predictions on the second part and evaluate the predictions against the expected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 Training and testing datasets using : train_test_split()\n",
    "\n",
    "- The size of the split can depend on the size and specifics of your dataset.\n",
    "- It is common to use 67% of the data for training and the remaining 33% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.33\n",
    "seed = 7\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Compute the estimated accuracy for the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.74015748031496\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "result = model.score(X_test, Y_test)\n",
    "\n",
    "print(\"Accuracy:\",result*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- K-fold Cross Validation\n",
    "\n",
    "- Cross validation is an approach that you can use to estimate the performance of a machine learning algorithm with less variance than a single train-test set split. \n",
    "- It works by splitting the dataset into k-parts (e.g. k = 5 or k = 10). \n",
    "    - Each split of the data is called a fold. \n",
    "    - The algorithm is trained on k âˆ’ 1 folds with one held back and tested on the held back fold.\n",
    "    \n",
    "- The result is a more reliable estimate of the performance of the algorithm on new data. \n",
    "- It is more accurate because the algorithm is trained and evaluated multiple times on different data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Call KFold()\n",
    "\n",
    "- The choice of k must allow the size of each test partition to be large enough to be a reasonable sample of the problem.\n",
    "\n",
    "- For modest sized datasets in the thousands or tens of thousands of records, k values of 3, 5 and 10 are common. In the example below we use 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.2 Compute the mean and the standard deviation of the performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  (77.21633629528367, 4.96837651757489)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: \", (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Leave One Out Cross Validation\n",
    "\n",
    "- You can configure cross validation so that the size of the fold is 1 (k is set to the number of observations in your dataset). \n",
    "- This variation of cross validation is called leave-one-out cross validation. \n",
    "- The result is a large number of performance measures that can be summarized in an effort to give a more reasonable estimate of the accuracy of your model on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Call LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loocv = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.2 Compute the mean and the standard deviation of the performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  (77.60416666666666, 41.68944689773287)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=250)\n",
    "results = cross_val_score(model, X, Y, cv=loocv)\n",
    "print(\"Accuracy: \",(results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Repeated Random Test-Train Splits\n",
    "\n",
    "- Another variation on k-fold cross validation is to create a random split of the data like the train/test split described above, but repeat the process of splitting and evaluation of the algorithm multiple times, like cross validation.\n",
    "- This has the speed of using a train/test split and the reduction in variance in the estimated performance of k-fold cross validation. \n",
    "- You can also repeat the process many more times as needed to improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Call ShuffleSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.2 Compute the mean and the standard deviation of the performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  (76.53543307086613, 2.235444026232818)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: \" , (results.mean()*100.0, results.std()*100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
