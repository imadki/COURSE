{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithm Performance Metrics\n",
    "\n",
    "- The metrics that you choose to evaluate your machine learning algorithms are very important.\n",
    "- Choice of metrics influences how the performance of machine learning algorithms is measured and compared. \n",
    "- They influence how you weight the importance of different characteristics in the results and your ultimate choice of which algorithm to choose.\n",
    "\n",
    "- Algorithm Evaluation Metrics :\n",
    "    - Classification metrics (Pima Indians onset of diabetes dataset is used as demonstration).\n",
    "    - Regression metrics (the Boston House Price dataset is used as demonstration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Classification Accuracy\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "filename = 'data/05/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification Metrics\n",
    "\n",
    "- Classification problems are perhaps the most common type of machine learning problem and as such there are a myriad of metrics that can be used to evaluate predictions for these problems.\n",
    "- In this section we will review how to use the following metrics:\n",
    "\n",
    "    - Classification Accuracy.\n",
    "    - Logarithmic Loss.\n",
    "    - Area Under ROC Curve.\n",
    "    - Confusion Matrix.\n",
    "    - Classification Report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Classification Accuracy\n",
    "\n",
    "- Classification accuracy is the number of correct predictions made as a ratio of all predictions made. \n",
    "- This is the most common evaluation metric for classification problems, it is also the most misused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kissami/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  (0.7760423786739576, 0.051575452620868226)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7, shuffle=False)\n",
    "model = LogisticRegression(max_iter=200)\n",
    "scoring = 'accuracy'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: \", (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This can be converted into a percentage by multiplying the value by 100, giving an accuracy score of approximately 77% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Logarithmic Loss\n",
    "\n",
    "- Logarithmic loss (or logloss) is a performance metric for evaluating the predictions of probabilities of membership to a given class.\n",
    "- The scalar probability between 0 and 1 can be seen as a measure of confidence for a prediction by an algorithm. \n",
    "- Predictions that are correct or incorrect are rewarded or punished proportionally to the confidence of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kissami/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss:  (-0.48446261206673835, 0.06168124033613043)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7, shuffle=False)\n",
    "model = LogisticRegression(max_iter=200)\n",
    "scoring = 'neg_log_loss'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Logloss: \", (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Smaller logloss is better with 0 representing a perfect logloss. \n",
    "- As mentioned above, the measure is inverted to be ascending when using the cross val score() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3  Area Under ROC Curve \n",
    "\n",
    "- Area under ROC Curve (or AUC for short) is a performance metric for binary classification problems. \n",
    "- The AUC represents a model's ability to discriminate between positive and negative classes. \n",
    "- An area of 1.0 represents a model that made all predictions perfectly. \n",
    "- An area of 0.5 represents a model that is as good as random. ROC can be broken down into sensitivity and specificity. \n",
    "- A binary classification problem is really a trade-off between sensitivity and specificity.\n",
    "    - Sensitivity is the true positive rate also called the recall. It is the number of instances from the positive (first) class that actually predicted correctly.\n",
    "    - Specificity is also called the true negative rate. Is the number of instances from the negative (second) class that were actually predicted correctly.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kissami/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  (0.8280337127246062, 0.04287108616940878)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7, shuffle=False)\n",
    "model = LogisticRegression(max_iter=200)\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"AUC: \",(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can see the AUC is relatively close to 1 and greater than 0.5, suggesting some skill inthe predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Confusion Matrix\n",
    "\n",
    "- The confusion matrix is a handy presentation of the accuracy of a model with two or more classes. \n",
    "- The table presents predictions on the x-axis and accuracy outcomes on the y-axis. \n",
    "- The cells of the table are the number of predictions made by a machine learning algorithm. \n",
    "- For example, a machine learning algorithm can predict 0 or 1 and each prediction may actually have been a 0 or 1. \n",
    "- Predictions for 0 that were actually 0 appear in the cell for prediction = 0 and actual = 0, whereas predictions for 0 that were actually 1 appear in the cell for prediction = 0 and actual = 1. \n",
    "- And so on. Below is an example of calculating a confusion matrix for a set of predictions by a Logistic Regression on the Pima Indians onset of diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142  20]\n",
      " [ 34  58]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Although the array is printed without headings, you can see that the majority of the predictions fall on the diagonal line of the matrix (which are correct predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Classification Report\n",
    "\n",
    "- The scikit-learn library provides a convenience report when working on classification problems to give you a quick idea of the accuracy of a model using a number of measures. \n",
    "- The classification report() function displays the precision, recall, F1-score and support for each class. \n",
    "- The example below demonstrates the report on the binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can see good prediction and recall for the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.88      0.84       162\n",
      "         1.0       0.74      0.63      0.68        92\n",
      "\n",
      "    accuracy                           0.79       254\n",
      "   macro avg       0.78      0.75      0.76       254\n",
      "weighted avg       0.78      0.79      0.78       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Regression Metrics\n",
    "\n",
    "- In this section will review 3 of the most common metrics for evaluating predictions on regression machine learning problems:\n",
    "    - Mean Absolute Error.\n",
    "    - Mean Squared Error.\n",
    "    - $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/05/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "dataframe\n",
    "\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Mean Absolute Error\n",
    "\n",
    "- The Mean Absolute Error (or MAE) is the sum of the absolute differences between predictions and actual values. \n",
    "- It gives an idea of how wrong the predictions were. \n",
    "- The measure gives an idea of the magnitude of the error, but no idea of the direction (e.g. over or under predicting).\n",
    "- The example below demonstrates calculating mean absolute error on the Boston house price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kissami/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7, shuffle=False)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A value of 0 indicates no error or perfect predictions. Like logloss, this metric is inverted by the cross val score() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: (-4.004946635323988, 2.0835992687095364)\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE:\", (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Mean Squared Error\n",
    "\n",
    "- The Mean Squared Error (or MSE) is much like the mean absolute error in that it provides a gross idea of the magnitude of error. \n",
    "- Taking the square root of the mean squared error converts the units back to the original units of the output variable and can be meaningful for description and presentation. \n",
    "- This is called the Root Mean Squared Error (or RMSE). \n",
    "- The example below provides a demonstration of calculating mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kissami/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle=False)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This metric too is inverted so that the results are increasing. Remember to take the absolute value before taking the square root if you are interested in calculating the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  (-34.70525594452488, 45.57399920030877)\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: \", (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 $R^2$ Metric\n",
    "- The $R^2$ (or R Squared) metric provides an indication of the goodness of fit of a set of predictions to the actual values. \n",
    "- In statistical literature this measure is called the coefficient of determination.\n",
    "- This is a value between 0 and 1 for no-fit and perfect fit respectively. The example below provides a demonstration of calculating the mean $R^2$ for a set of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kissami/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7, shuffle=False)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can see the predictions have a poor fit to the actual values with a value closer to zero and less than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  (0.20252899006055963, 0.5952960169512322)\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2: \", (results.mean(), results.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
